---
title: "STA_478_Final_Project"
author: "Crystal Sawtelle"
date: "2022-11-28"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(ISLR)) install.packages("ISLR")
if (!require(rpart)) install.packages("rpart")
if (!require(rpart.plot)) install.packages("rpart.plot")
if (!require(caret)) install.packages("caret")
if (!require(mgcv)) install.packages("mgcv")
if (!require(MASS)) install.packages("MASS")
if (!require(tree)) install.packages('tree')
if (!require(tidyverse)) install.packages('tidyverse')
if (!require(glmnet)) install.packages("glmnet")
if (!require(fastDummies)) install.packages("fastDummies")
```

## Introduction
  
  This data was generated by a large US company that was concerned with the high turnover the company was experiencing. They wanted to understand why people were leaving and try to predict which employees would more than likely leave. The data includes almost 10,000 employee responses who left the company between 2016 and 2020, collecting the data from exit interviews, performance reviews, and employee records. This data was chosen because it contained a lot of information, both categorical and numerical. It is a good dataset to practice the skills learned to become more comfortable with these processes. 
  
## Data evaluation

  There are 10 variables in this data set with 9,540 observations. The first is the department the employee works in. Most employees work or worked in four departments, engineering, operations, retail and sales. The next parameter is promoted, 1 if the employee was promoted in the last 24 months or 0 if not. The company appears to only promote from within about 3% of the time. Review is the score on the last evaluation the employee received. The mean of the reviews is 0.6518 points with a standard deviation of about 0.09 points. Reviewing the boxplot, there appear to be quite a few high and low outliers. Satisfaction is the measure of how satisfied the employee reported to be on their last employee satisfaction survey. The mean and the median of the data is 0.50 points with a standard deviation of 0.16 points, The boxplot shows there are not many outliers in the satisfaction scores. Projects is the number of projects the employee was involved in. Most employees have 2, 3 or 4 active projects with a few having 5. Salary is categorical with low, medium, and high. Almost 70% of the employees have or had a medium sized salary. Approximately 14% have or had a low salary and approximately 16% have or had a high salary. How many years an employee was at the company is tenure. The mean of tenure is about 6.56 years and a median of 7 years. The standard deviation is about 1.42 years. Bonus records whether an employee received a bonus in the last 24 months, 1, or 0 if not. Only about 21% of employees have received a bonus in the last 24 months. Avg_hrs_month records the average amount of hours the employee worked in a month. The mean and median for average hours worked in a month are 184.66 and 184.63 respectively with a standard deviation of about 4.14 hours a month. If we assume a 40 hour work week, the average amount of overtime the employees are getting in a month is about 24 hours or 6 hours of overtime a week. There are a few outliers of employees working more than 195 hours a month. Finally, there is left which records if the employee left the company or not. Approximately 29% of employees have left the company for some reason or another.

  
  The first data cleaning that was performed on this dataset was changing bonus and promoted from zeros and ones to Yes and No. This was done so that the data would be easier to interpret when analyzing while performing the generalized additive model. An additional change was left from yes and no to Yes and No to keep consistant with the changes to bonus and promoted.
  
```{r, echo=FALSE}
rm(list=ls())
library(readr)
employee_turn <- read_csv("~/NAU Folders/NAU Fall 2022/STA 478 Statistical Computing/Final Project Data/employee_churn_data.csv")

employee_turn <- employee_turn %>%
  mutate(bonus = ifelse(bonus == 1, 'Yes', 'No')) %>%
  mutate(promoted = ifelse(promoted == 1, 'Yes', 'No')) %>%
  mutate(left = ifelse(left == 'yes', 'Yes', 'No'))

head(employee_turn)
save(employee_turn, file='employee_turn.rda')
```

  
  The only way to do a regression model with categorical data is by creating dummy variables for each categorical variable. This data has five such categorical columns: department, promoted, projects, salary, and bonus. Downloaded fastDummies package, converted them and then removed the original columns. Additionally, the left column needed to be changed from yes and no's to 1's and 0's in order to find the MSE for the ridge, elastic-net, and lasso methods.

```{r, echo=FALSE}
employee.turn.reg <- read_csv("~/NAU Folders/NAU Fall 2022/STA 478 Statistical Computing/Final Project Data/employee_churn_data.csv")
employee.turn.reg <- dummy_cols(employee.turn.reg, select_columns = c("department", "promoted", "projects", "salary", "bonus"))

# remove columns that were turned into dummy variables
employee.turn.reg <- employee.turn.reg %>%
  select(-one_of('department', 'promoted', 'projects', 'salary', 'bonus')) %>%
  mutate(left = ifelse(left == 'yes', 1, 0))

head(employee.turn.reg)
save(employee.turn.reg, file='employee.turn.reg.rda')
```


## Modeling introduction 
  
  The first model that was chosen was the generalize linear model (GLM). This model was chosen because response variable is a categorical variable and it allows for a good indication of what variables would be significant in the final model. The second model chosen was a generalize additive model (GAM), which was chosen to slowly analyze the data to find the significant variables and to see if any of the variables were non-linear. A for loop was created to find the best alpha and lambda to determine which process would produce the best model, Ridge, Elastic-net, or LASSO. It was determined that the LASSO had the smallest lambda and a LASSO regression model was produced. 
  
```{r, echo=FALSE}
model <- glm(I(left=='Yes') ~ department + promoted + review + projects + salary + tenure + satisfaction + bonus + avg_hrs_month, data = employee_turn, family = binomial())
summary(model)
```
  
  The GAM was implemented by first splitting the dataset into 70% train and 30% test. Next I ran a generalized additive model without smoothing and found the log error. Next I ran the model with smoothing. A limitation I ran into was I could only smooth four of the variables (review, tenure, satisfaction, and avg_hrs_month) because the rest are categorical type variables. The log error went down to 19% and there is definitely non-linear relationships for review and avg_hrs_month. I then removed the department variable because it contained the hightest p-values. I then removed tenure with the next highest p-value (0.876). Followed by salary (p-value = 0.7788 and 0.7383), bonus (p-value 0.6016) and lastly projects (p-value =0.1483).
  
  The next analysis I perfomed was the lasso, ridge, and elastic-net regression. It was implemented by creating a for loop that would give me the all the MSE's between 0 and 1, increasing by a 10th for each loop, and determining which alpha produced the lowest lambda. The lowest lambda was the lasso. I then did a bootstrap on the lasso coefficients to verify the resulting variables were significant. 
  
  Since there was a lot of categorical data, I wanted to see if there was any correlation between a few of the variables. I chose to compare department vs. left, salary vs. bonus, salary vs. promoted, and department vs. bonus. For department vs. left the highest turnover was found in the IT and logistics department at 45% of their workforce left between 2016 and 2020 and the lowest was in finance at 37%. However, the range for all the departments were between 37% and 45%, meaning no one department stood out as losing more employees than another. The same is true for salary vs. bonus, the range is between 26% and 29% with salary_low having the highest amount of bonuses. There was also no indication that salary played a role in whether someone was promoted, all three salary levels were promoted at the same rate, 3%. Lastly, department vs. bonus, the range for bonus between departments was 23% to 30%, the highest range thus far. One thing that did stand out is that finance gave the highest percent of bonuses and they had the lowest percentage in turnover. But there is not enough evidence across all departments to say that is an issue overall.
  
```{r, echo=FALSE, eval=FALSE}
table(employee_turn$department, employee_turn$left)
table(employee_turn$salary, employee_turn$bonus)
table(employee_turn$salary, employee_turn$promoted)
table(employee_turn$department, employee_turn$bonus)
```
| Department/Left |      |      |     |
|-----------------|------|------|-----|
|                 | No   | Yes  |     |
| admin           | 304  | 119  | 39% |
| engineering     | 1079 | 437  | 41% |
| finance         | 294  | 108  | 37% |
| IT              | 246  | 110  | 45% |
| logistics       | 249  | 111  | 45% |
| marketing       | 559  | 243  | 43% |
| operations      | 1086 | 436  | 40% |
| retail          | 1070 | 471  | 44% |
| sales           | 1346 | 537  | 40% |
| support         | 523  | 212  | 41% |
|-----------------|------|------|-----|
|                 | 6756 | 2784 | 41% |


| Salary/Bonus |      |      |     |
|--------------|------|------|-----|
|              | No   | Yes  |     |
| high         | 1217 | 331  | 27% |
| low          | 1070 | 311  | 29% |
| medium       | 5230 | 1381 | 26% |
|--------------|------|------|-----|
|              | 7517 | 2023 | 27% |


| Salary/Promoted |      |     |    |
|-----------------|------|-----|----|
|                 | No   | Yes |    |
| high            | 1502 | 46  | 3% |
| low             | 1341 | 40  | 3% |
| medium          | 6408 | 203 | 3% |
|-----------------|------|-----|----|
|                 | 9251 | 289 | 3% |


| Department/Bonus |      |      |     |
|------------------|------|------|-----|
|                  | No   | Yes  |     |
| admin            | 344  | 79   | 23% |
| engineering      | 1196 | 320  | 27% |
| finance          | 309  | 93   | 30% |
| IT               | 277  | 79   | 29% |
| logistics        | 285  | 75   | 26% |
| marketing        | 626  | 176  | 28% |
| operations       | 1207 | 315  | 26% |
| retail           | 1204 | 337  | 28% |
| sales            | 1484 | 399  | 27% |
| support          | 585  | 150  | 26% |
|------------------|------|------|-----|
|                  | 7517 | 2023 | 27% |


## Analysis results/Discussion of final models and analysis

  For the GAM model, looking at the summary it appears that most of the variables are not significant indicators of whether an employee may leave the company. Leaving only three variables with significance; promotedYes, review, and satisfaction. For the log error it is reporting that 27% are not predicting correctly. There were only four variables (review, tenure, satisfaction, and avg_hrs_month) that I could smooth because the rest are categorical type variables. 
  
```{r, echo=FALSE}
set.seed(578)
employee.shuffle <- employee_turn[sample(c(1:nrow(employee_turn)), nrow(employee_turn)),]

sample_size <- floor(0.7*nrow(employee.shuffle))
sample_70 <- sample(seq_len(nrow(employee.shuffle)), size = sample_size)
employee.train <- employee_turn[sample_70,]
employee.test <- employee_turn[-sample_70,]
```

```{r, echo=FALSE}
employee.gam <- gam(I(left == 'Yes') ~ department + promoted + review + projects + salary + tenure + satisfaction + bonus + avg_hrs_month, family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam)

fit.log.preds <- predict(employee.gam, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
print(paste0("Log Error for unsmoothed GAM model: (",log.error,")"))
```

The log error went down to 19% and there is definitely non-linear relationships for review and avg_hrs_month. Department, tenure, salary, bonus and projects were then removed in order. The log error did not improve since the original smoothing of the model, it stayed steady at 19% error rate. This is not a bad error rate, 19% were misclassified in the test data. The final model to predict if an employee is more than likely to leave the company using a generalized additive model includes the variables promoted, review, satisfaction, and avg_hrs_month.

```{r, echo=FALSE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ department + promoted + s(review) + projects + salary + s(tenure) + s(satisfaction) + bonus + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
log.error

plot(employee.gam.smooth)
```

```{r, echo=FALSE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ promoted + s(review) + projects + salary + s(tenure) + s(satisfaction) + bonus + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
log.error

#plot(employee.gam.smooth)
```

```{r, echo=FALSE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ promoted + s(review) + projects + salary + s(satisfaction) + bonus + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
log.error

#plot(employee.gam.smooth)
```

```{r, echo=TRUE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ promoted + s(review) + projects + s(satisfaction) + bonus + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
log.error

#plot(employee.gam.smooth)
```

```{r, echo=FALSE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ promoted + s(review) + projects + s(satisfaction) + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
log.error

#plot(employee.gam.smooth)
```

  
  The log error did not improve since I smoothed the gam, it stayed steady at 19% error rate. This is not a bad error rate, 19% were misclassified in the test data. The final model to predict if an employee is more than likely to leave the company using a generalized additive model includes the variables promoted, review, satisfaction, and avg_hrs_month.
  
  $$\hat{\text{left}} = -20.16 - 0.76(\text{promotedYes}) + 10.99(\text{review}) + 2.42(\text{satisfaction})+0.06(\text{avg_hrs_month})$$
  
  Since the model's intercept is -20.16, the higher the scores for review, satisfaction, and avg_hrs_month, the less likely the employee will leave the company. If an employee was promoted their likelihood of leaving went down by 0.76. For every increase in review score, the likelihood of the employee leaving goes down by 10.99. The employees satisfaction score decreased their likelihood of leaving by 2.42 and as their avg_hrs_month go up, the likelihood of leaving goes down. Apparently people like overtime. 
  
```{r, echo=FALSE}
employee.gam.smooth <- gam(I(left == 'Yes') ~ promoted + s(review) + s(satisfaction) + s(avg_hrs_month), family = "binomial", data = employee.train, method = 'REML')
summary(employee.gam.smooth)

fit.log.preds <- predict(employee.gam.smooth, newdata = employee.test, type = 'response')
fit.log.preds <- ifelse(fit.log.preds > 0.5, 1, 0)
log.error = mean(fit.log.preds != I(employee.test$left == 'Yes'))
print(paste0("Log Error for smoothed GAM model: (",log.error,")"))

plot(employee.gam.smooth, pages = 1, rug = TRUE)

employee.gam.final <- gam(I(left == 'Yes') ~ promoted + review + satisfaction + avg_hrs_month, family = "binomial", data = employee.train, method = 'REML'); summary(employee.gam.final)
```


  Using 30% of the employee turnover data with the dummy variables I did a 10,000 sample bootstrap on the lasso coefficients review, satisfaction, avg_hrs_month, department_finance, department_IT, department_retail, promoted_no, projects_4, salary_medium, and bonus_no. The bootstrap returned department_finance, department_IT, department_retail, projects_4, salary_medium and bonus_no as insignificant. Using the lasso model, the final model includes review, satisfaction, avg_hrs_month and promoted_no. These results coincide with the generalized additive model above.
  
```{r, echo=FALSE}
x = model.matrix(left~., data=employee.turn.reg)[,-1]
y = employee.turn.reg$left

grid = 10^seq(10, -2, length=100)
ridge.mod = glmnet(x,y, alpha=0, lambda=grid)

set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]

```


I found (at https://youtu.be/ctmNq7FgbvI "Ridge, Lasso and Elastic-Net Regression in R") and modify an elastic regression code that used a for loop to find all MSE's between 0 and 1 (increasing by a 10th each loop). Using this code I found that the smallest MSE is the Lasso regression with an MSE of 2.149864 and an accuracy of 1.466. Alpha = 0.2 was a close second with an MSE of 2.149940. I then processed the LASSO regression on the data. This returned the lasso coefficients: review, satisfaction, avg_hrs_month, department_finance, department_IT, department_retail, promoted_no, projects_4, salary_medium, and bonus_no

```{r, echo=FALSE}
set.seed(1)
alpha.name <- list()

for (i in 0:10){
  
  ENET.fit <- paste0("alpha", i/10)
  
  alpha.name[[ENET.fit]] <- glmnet(x[train,], y[train], family = 'binomial', 
                           alpha=i/10, lambda=grid)
}

results <- data.frame()
for (i in 0:10){
  ENET.fit <- paste0("alpha", i/10)
  
  cv.out = cv.glmnet(x[train,], y[train], alpha=i/10) 
  bestlam = cv.out$lambda.min
  
  ENET.pred = predict(alpha.name[[ENET.fit]], s = bestlam, family = 'binomial', newx=x[test,])
  ENET.MSE <- mean((ENET.pred - y.test)^2); ENET.MSE
  
  temp <- data.frame(alpha = i/10, ENET.MSE=ENET.MSE, Alpha.fit = ENET.fit, Best.Lambda = bestlam)
  results <- rbind(results, temp)
}
results
```


```{r, echo=FALSE}
lasso.mod = glmnet(x[train,], y[train], family = 'binomial', alpha=1, lambda=grid)
cv.out = cv.glmnet(x[train,], y[train], alpha=1) 
bestlam = cv.out$lambda.min
bestlam

lasso.pred = predict(lasso.mod, s = bestlam, family = 'binomial', newx=x[test,])
lasso.MSE <- mean((lasso.pred - y.test)^2); lasso.MSE

out = glmnet(x, y, alpha=1)
lasso.coef = predict(out, type="coefficients", s=bestlam) [1:26,]
lasso.coef

lasso.coef[lasso.coef!=0]
```
  
  
  Using 30% of the employee turnover data with the dummy variables I did a bootstrap on the lasso coefficients review, satisfaction, avg_hrs_month, department_finance, department_IT, department_retail, promoted_no, projects_4, salary_medium, and bonus_no. Using the histograms the bootstrap returned department_finance, department_IT, department_retail, projects_4, salary_medium and bonus_no as insignificant variables. Using the lasso model, the final model includes review, satisfaction, and avg_hrs_month. The difference between the GAM model and the Lasso bootstrap is promoted.

  The final model is:
  
  $$\hat{\text{left}} = -3.24 + 1.98(\text{review}) + 0.39(\text{satisfaction}) + 0.01(\text{avg_hrs_month})$$
  The model's intercept is -3.24, the higher the scores for review, satisfaction, and avg_hrs_month, the less likely the employee will leave the company. For every increase in review score, the likelihood of the employee leaving goes down by 1.98. The employees satisfaction score decreased their likelihood of leaving by 0.39 and as their avg_hrs_month go up, the likelihood of leaving goes down by 0.01. 
  

```{r, cache=TRUE, echo=FALSE}
set.seed(1)
n.bootstap.samples = 10000

employee.sample = employee.turn.reg[sample(seq(1:nrow(employee.turn.reg)), nrow(employee.turn.reg)*.30),]

review.coef <- c()
satisfaction.coef <- c()
avg.hrs.month.coef <- c()
department.finance.coef <- c()
department.IT.coef <- c()
department.retail.coef <- c()
promoted.0.coef <- c()
projects.4.coef <- c()
salary.medium.coef <- c()
bonus.0.coef <- c()



for (sample in 1:n.bootstap.samples) {

  bootstrap_sample = employee.sample[sample(seq(1:nrow(employee.sample)), nrow(employee.sample), 
                                           replace=TRUE),]
  
  x.employee = model.matrix(I(left==1)~review+satisfaction+avg_hrs_month+department_finance+department_IT+department_retail+promoted_0+projects_4+salary_medium+bonus_0, data=bootstrap_sample)
  y.employee = bootstrap_sample$left
  
  train = sample(1:nrow(x.employee), nrow(x.employee)*.7)
  test = (-train)
  y.test = y[test]
  
  bs.data = cv.glmnet(x.employee[train,], y.employee[train], alpha=1)
  bestlam = bs.data$lambda.min
  lasso.coef = predict(bs.data, type='coefficients', s = bestlam, newx=x.employee[test,]) [1:12]

  review.coef <- append(review.coef, lasso.coef[3])
  satisfaction.coef <- append(satisfaction.coef, lasso.coef[4])
  avg.hrs.month.coef <- append(avg.hrs.month.coef, lasso.coef[5])
  department.finance.coef <- append(department.finance.coef, lasso.coef[6])
  department.IT.coef <- append(department.IT.coef, lasso.coef[7])
  department.retail.coef <- append(department.retail.coef, lasso.coef[8])
  promoted.0.coef <- append(promoted.0.coef, lasso.coef[9])
  projects.4.coef <- append(projects.4.coef, lasso.coef[10])
  salary.medium.coef <- append(salary.medium.coef, lasso.coef[11])
  bonus.0.coef <- append(bonus.0.coef, lasso.coef[12])


}

```

```{r, echo=FALSE}
par(mfrow = c(2, 2))
hist(review.coef, main = "Review")
beta.1.q0.025 = quantile(review.coef, 0.025)
abline(v=beta.1.q0.025,col="blue",lwd=2, lty="dashed")
beta.1.q0.975 = quantile(review.coef, 0.975)
abline(v=beta.1.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Review is: (", beta.1.q0.025, ",", beta.1.q0.975,")"))

hist(satisfaction.coef, main = "Satisfaction")
beta.2.q0.025 = quantile(satisfaction.coef, 0.025)
abline(v=beta.2.q0.025,col="blue",lwd=2, lty="dashed")
beta.2.q0.975 = quantile(satisfaction.coef, 0.975)
abline(v=beta.2.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Satisfaction is: (", beta.2.q0.025, ",", beta.2.q0.975,")"))

hist(avg.hrs.month.coef, main = "Average Hours per Month")
beta.3.q0.025 = quantile(avg.hrs.month.coef, 0.025)
abline(v=beta.3.q0.025,col="blue",lwd=2, lty="dashed")
beta.3.q0.975 = quantile(avg.hrs.month.coef, 0.975)
abline(v=beta.3.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Average Hours per Month is: (", beta.3.q0.025, ",", beta.3.q0.975,")"))

hist(department.finance.coef, main = "Depart.Finance")
beta.4.q0.025 = quantile(department.finance.coef, 0.025)
abline(v=beta.4.q0.025,col="blue",lwd=2, lty="dashed")
beta.4.q0.975 = quantile(department.finance.coef, 0.975)
abline(v=beta.4.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Depart.Finance is: (", beta.4.q0.025, ",", beta.4.q0.975,")"))

par(mfrow = c(2, 2))
hist(department.IT.coef, main = "Depart.IT")
beta.5.q0.025 = quantile(department.IT.coef, 0.025)
abline(v=beta.5.q0.025,col="blue",lwd=2, lty="dashed")
beta.5.q0.975 = quantile(department.IT.coef, 0.975)
abline(v=beta.5.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Depart.IT is: (", beta.5.q0.025, ",", beta.5.q0.975,")"))

hist(department.retail.coef, main = "Depart.Retail")
beta.6.q0.025 = quantile(department.retail.coef, 0.025)
abline(v=beta.6.q0.025,col="blue",lwd=2, lty="dashed")
beta.6.q0.975 = quantile(department.retail.coef, 0.975)
abline(v=beta.6.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Depart.Retail is: (", beta.6.q0.025, ",", beta.6.q0.975,")"))

hist(promoted.0.coef, main = "Promoted.No")
beta.7.q0.025 = quantile(promoted.0.coef, 0.025)
abline(v=beta.7.q0.025,col="blue",lwd=2, lty="dashed")
beta.7.q0.975 = quantile(promoted.0.coef, 0.975)
abline(v=beta.7.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Promoted.No is: (", beta.7.q0.025, ",", beta.7.q0.975,")"))

hist(projects.4.coef, main = "Project.4")
beta.8.q0.025 = quantile(projects.4.coef, 0.025)
abline(v=beta.8.q0.025,col="blue",lwd=2, lty="dashed")
beta.8.q0.975 = quantile(projects.4.coef, 0.975)
abline(v=beta.8.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Project.4 is: (", beta.8.q0.025, ",", beta.8.q0.975,")"))

par(mfrow = c(1, 2))
hist(salary.medium.coef, main = "Salary.medium")
beta.9.q0.025 = quantile(salary.medium.coef, 0.025)
abline(v=beta.9.q0.025,col="blue",lwd=2, lty="dashed")
beta.9.q0.975 = quantile(salary.medium.coef, 0.975)
abline(v=beta.9.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Salary.Medium is: (", beta.9.q0.025, ",", beta.9.q0.975,")"))

hist(bonus.0.coef, main = "Bonus.No")
beta.10.q0.025 = quantile(bonus.0.coef, 0.025)
abline(v=beta.10.q0.025,col="blue",lwd=2, lty="dashed")
beta.10.q0.975 = quantile(bonus.0.coef, 0.975)
abline(v=beta.10.q0.975,col="blue",lwd=2, lty="dashed")
print(paste0("Our 95% CI for the Drivers Bonus.No is: (", beta.10.q0.025, ",", beta.10.q0.975,")"))

```

```{r, echo=FALSE}
lasso.final.model <- glm(I(left==1)~review+satisfaction+avg_hrs_month, data=employee.turn.reg)
summary(lasso.final.model)
```

## Conclusions

  This project has taught me to better understand the model selection procedures and to better analyze the results. I still have a long way to go before I am anywhere near proficient at model selection and analysis, but I feel more confident in my abilities because of this project. For future projects, I would like to try other model selection techniques like tree-based modeling. The data I selected was easy to use and easy to predict. In the future, I would like to try data that I have collected to analyze and predict.

## Appendix
```{r show-code, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```





